{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "クローリングを開始します\n",
      "アーティスト名: 演歌\n",
      "過剰な連続リクエスト回避のsleep:5秒\n",
      "演歌の1 ページ目のクローリングを開始...\n",
      "1ページ目取得完了...\n",
      "演歌の1ページ目の保存中...\n",
      "演歌の1 ページ目のクローリングを完了しました。\n",
      "過剰な連続リクエスト回避のsleep:5秒\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "全アーティストのクローリングを完了しました\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#演歌は母数が少なすぎるので、Yahooオークションにて「演歌　チケット」の検索結果を全件取得するものとする\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "#2019-03-12みたいな日付けを作る\n",
    "def formatted_today():\n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    today = \"{0:%Y-%m-%d}\".format(now)\n",
    "    return today\n",
    "\n",
    "def print_line():\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "def sleep_(sec):\n",
    "    print(\"過剰な連続リクエスト回避のsleep:\"+str(sec)+\"秒\")\n",
    "    sleep(sec)\n",
    "\n",
    "    \n",
    "    \n",
    "def get_save(query_name, url):\n",
    "    \n",
    "    print(\"クローリングを開始します\")\n",
    "    print(\"アーティスト名: \"+query_name)\n",
    "\n",
    "    \n",
    "#     試しに一回取得\n",
    "    r = requests.get(url)\n",
    "    soup  = BeautifulSoup(r.text,\"html.parser\").body\n",
    "    sleep_(5)\n",
    "\n",
    "\n",
    "    last_page = \"1\"\n",
    "#     1→63までループ\n",
    "    for i in range(1, int(last_page)+1):\n",
    "\n",
    "        print(query_name+\"の\"+str(i)+\" ページ目のクローリングを開始...\")\n",
    "\n",
    "        url += (\"&pn=\" +last_page)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        print(str(i)+\"ページ目取得完了...\")\n",
    "# 日付けからディレクトリ作成\n",
    "        date = formatted_today()\n",
    "        combined_path = query_name+\"/\"+date\n",
    "        os.makedirs(combined_path, exist_ok=True)\n",
    "#     書き込み\n",
    "        with open (combined_path+\"/\"+\"ticket-data\"+str(i)+\".html\", mode=\"w\", encoding=\"utf-8\") as fw:\n",
    "            fw.write(soup.prettify())\n",
    "            print(query_name+\"の\"+str(i)+\"ページ目の保存中...\")\n",
    "\n",
    "        print(query_name+\"の\"+str(i)+\" ページ目のクローリングを完了しました。\")\n",
    "        sleep_(5)\n",
    "\n",
    "\n",
    "# get_save(url, name)\n",
    "\n",
    "url = \"https://auctions.yahoo.co.jp/category/list/%E9%9F%B3%E6%A5%BD-%E8%88%88%E8%A1%8C%E3%83%81%E3%82%B1%E3%83%83%E3%83%88-%E3%83%81%E3%82%B1%E3%83%83%E3%83%88-%E9%87%91%E5%88%B8-%E5%AE%BF%E6%B3%8A%E4%BA%88%E7%B4%84/2084059686/?p=%E6%BC%94%E6%AD%8C&auccat=50060&exflg=1&b=1&n=100&s1=featured&isdd=0\"\n",
    "name =\"演歌\"\n",
    "get_save(name,url)\n",
    "\n",
    "\n",
    "print_line()\n",
    "print(\"全アーティストのクローリングを完了しました\")\n",
    "print_line()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
